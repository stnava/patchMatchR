% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/patchMatch.R
\name{deepPatchMatch}
\alias{deepPatchMatch}
\title{patch match two images with deep features}
\usage{
deepPatchMatch(movingImage, fixedImage, movingImageMask, fixedImageMask,
  movingPatchSize = 32, fixedPatchSize = 32, knn = 1,
  visualize = FALSE)
}
\arguments{
\item{movingImage}{input image from which we extract patches that are
transformed to the space of the fixed image}

\item{fixedImage}{input image that provides the fixed reference domain.}

\item{movingImageMask}{defines the object of interest in the movingImage}

\item{fixedImageMask}{defines the object of interest in the fixedImage}

\item{movingPatchSize}{integer greater than or equal to 32.}

\item{fixedPatchSize}{integer greater than or equal to 32.}

\item{knn}{k-nearest neighbors ( should be 1, for now )}

\item{visualize}{boolean}
}
\value{
correspondence data
}
\description{
High-level function for deep patch matching that makes many assumptions and
therefore minimizes the number of parameters the user needs to choose.
}
\examples{

library( keras )
library( ANTsR )
nP1 = 5
nP2 = 20
psz = 32
img <- ri( 1 ) \%>\% iMath( "Normalize" )
img2 <- ri( 2 ) \%>\% iMath( "Normalize" )
mask = randomMask( getMask( img ), nP1 )
mask2 = randomMask( getMask( img2 ), nP2 )
match = deepPatchMatch( img2, img, mask, mask2 )

}
\author{
Avants BB
}
